{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 654,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01529051987767584,
      "grad_norm": 11.022989273071289,
      "learning_rate": 1.9908256880733945e-05,
      "loss": 12.0231,
      "step": 10
    },
    {
      "epoch": 0.03058103975535168,
      "grad_norm": 155.26002502441406,
      "learning_rate": 1.980632008154944e-05,
      "loss": 13.7919,
      "step": 20
    },
    {
      "epoch": 0.045871559633027525,
      "grad_norm": 8.996129035949707,
      "learning_rate": 1.9704383282364936e-05,
      "loss": 13.1686,
      "step": 30
    },
    {
      "epoch": 0.06116207951070336,
      "grad_norm": 141.7963104248047,
      "learning_rate": 1.960244648318043e-05,
      "loss": 13.3416,
      "step": 40
    },
    {
      "epoch": 0.0764525993883792,
      "grad_norm": 44.24433517456055,
      "learning_rate": 1.9500509683995926e-05,
      "loss": 13.182,
      "step": 50
    },
    {
      "epoch": 0.09174311926605505,
      "grad_norm": 13.48249340057373,
      "learning_rate": 1.9398572884811417e-05,
      "loss": 13.0575,
      "step": 60
    },
    {
      "epoch": 0.10703363914373089,
      "grad_norm": 88.3427505493164,
      "learning_rate": 1.9296636085626912e-05,
      "loss": 12.4913,
      "step": 70
    },
    {
      "epoch": 0.12232415902140673,
      "grad_norm": 172.0810546875,
      "learning_rate": 1.9194699286442407e-05,
      "loss": 11.2284,
      "step": 80
    },
    {
      "epoch": 0.13761467889908258,
      "grad_norm": 149.57150268554688,
      "learning_rate": 1.9092762487257902e-05,
      "loss": 11.1828,
      "step": 90
    },
    {
      "epoch": 0.1529051987767584,
      "grad_norm": 16.117151260375977,
      "learning_rate": 1.8990825688073394e-05,
      "loss": 10.2954,
      "step": 100
    },
    {
      "epoch": 0.16819571865443425,
      "grad_norm": 20.483734130859375,
      "learning_rate": 1.888888888888889e-05,
      "loss": 9.0832,
      "step": 110
    },
    {
      "epoch": 0.1834862385321101,
      "grad_norm": 26.03529167175293,
      "learning_rate": 1.8786952089704384e-05,
      "loss": 9.9902,
      "step": 120
    },
    {
      "epoch": 0.19877675840978593,
      "grad_norm": 51.66054916381836,
      "learning_rate": 1.868501529051988e-05,
      "loss": 8.1638,
      "step": 130
    },
    {
      "epoch": 0.21406727828746178,
      "grad_norm": 163.2643280029297,
      "learning_rate": 1.8583078491335374e-05,
      "loss": 8.1312,
      "step": 140
    },
    {
      "epoch": 0.22935779816513763,
      "grad_norm": 52.623809814453125,
      "learning_rate": 1.848114169215087e-05,
      "loss": 7.9207,
      "step": 150
    },
    {
      "epoch": 0.24464831804281345,
      "grad_norm": 32.053035736083984,
      "learning_rate": 1.837920489296636e-05,
      "loss": 6.3753,
      "step": 160
    },
    {
      "epoch": 0.2599388379204893,
      "grad_norm": 79.20103454589844,
      "learning_rate": 1.8277268093781856e-05,
      "loss": 5.6334,
      "step": 170
    },
    {
      "epoch": 0.27522935779816515,
      "grad_norm": 27.640329360961914,
      "learning_rate": 1.817533129459735e-05,
      "loss": 4.9015,
      "step": 180
    },
    {
      "epoch": 0.290519877675841,
      "grad_norm": 27.43526268005371,
      "learning_rate": 1.8073394495412846e-05,
      "loss": 4.2102,
      "step": 190
    },
    {
      "epoch": 0.3058103975535168,
      "grad_norm": 17.84138298034668,
      "learning_rate": 1.797145769622834e-05,
      "loss": 4.2758,
      "step": 200
    },
    {
      "epoch": 0.3211009174311927,
      "grad_norm": 17.423583984375,
      "learning_rate": 1.7869520897043836e-05,
      "loss": 4.203,
      "step": 210
    },
    {
      "epoch": 0.3363914373088685,
      "grad_norm": 14.66960334777832,
      "learning_rate": 1.7767584097859328e-05,
      "loss": 2.4859,
      "step": 220
    },
    {
      "epoch": 0.3516819571865443,
      "grad_norm": 17.27591896057129,
      "learning_rate": 1.7665647298674823e-05,
      "loss": 2.6796,
      "step": 230
    },
    {
      "epoch": 0.3669724770642202,
      "grad_norm": 10.101943016052246,
      "learning_rate": 1.7563710499490318e-05,
      "loss": 2.3312,
      "step": 240
    },
    {
      "epoch": 0.382262996941896,
      "grad_norm": 14.564958572387695,
      "learning_rate": 1.746177370030581e-05,
      "loss": 1.9515,
      "step": 250
    },
    {
      "epoch": 0.39755351681957185,
      "grad_norm": 3.7078545093536377,
      "learning_rate": 1.7359836901121305e-05,
      "loss": 1.8833,
      "step": 260
    },
    {
      "epoch": 0.41284403669724773,
      "grad_norm": 3.6452858448028564,
      "learning_rate": 1.72579001019368e-05,
      "loss": 1.0571,
      "step": 270
    },
    {
      "epoch": 0.42813455657492355,
      "grad_norm": 2.051708221435547,
      "learning_rate": 1.7155963302752295e-05,
      "loss": 0.5912,
      "step": 280
    },
    {
      "epoch": 0.4434250764525994,
      "grad_norm": 1.3715555667877197,
      "learning_rate": 1.705402650356779e-05,
      "loss": 0.5931,
      "step": 290
    },
    {
      "epoch": 0.45871559633027525,
      "grad_norm": 0.9812724590301514,
      "learning_rate": 1.6952089704383285e-05,
      "loss": 0.5488,
      "step": 300
    },
    {
      "epoch": 0.4740061162079511,
      "grad_norm": 0.8181449770927429,
      "learning_rate": 1.6850152905198776e-05,
      "loss": 0.4319,
      "step": 310
    },
    {
      "epoch": 0.4892966360856269,
      "grad_norm": 0.8397002816200256,
      "learning_rate": 1.674821610601427e-05,
      "loss": 0.3806,
      "step": 320
    },
    {
      "epoch": 0.5045871559633027,
      "grad_norm": 0.7191246747970581,
      "learning_rate": 1.6646279306829766e-05,
      "loss": 0.3467,
      "step": 330
    },
    {
      "epoch": 0.5198776758409785,
      "grad_norm": 0.7541691064834595,
      "learning_rate": 1.654434250764526e-05,
      "loss": 0.315,
      "step": 340
    },
    {
      "epoch": 0.5351681957186545,
      "grad_norm": 0.7385095953941345,
      "learning_rate": 1.6442405708460757e-05,
      "loss": 0.3024,
      "step": 350
    },
    {
      "epoch": 0.5504587155963303,
      "grad_norm": 0.7344053387641907,
      "learning_rate": 1.634046890927625e-05,
      "loss": 0.2487,
      "step": 360
    },
    {
      "epoch": 0.5657492354740061,
      "grad_norm": 0.7197365164756775,
      "learning_rate": 1.6238532110091743e-05,
      "loss": 0.214,
      "step": 370
    },
    {
      "epoch": 0.581039755351682,
      "grad_norm": 0.7380478382110596,
      "learning_rate": 1.6136595310907238e-05,
      "loss": 0.1807,
      "step": 380
    },
    {
      "epoch": 0.5963302752293578,
      "grad_norm": 0.7074641585350037,
      "learning_rate": 1.6034658511722733e-05,
      "loss": 0.1453,
      "step": 390
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 1.5917141437530518,
      "learning_rate": 1.593272171253823e-05,
      "loss": 0.1116,
      "step": 400
    },
    {
      "epoch": 0.6269113149847095,
      "grad_norm": 0.6585666537284851,
      "learning_rate": 1.5830784913353723e-05,
      "loss": 0.0789,
      "step": 410
    },
    {
      "epoch": 0.6422018348623854,
      "grad_norm": 0.5678913593292236,
      "learning_rate": 1.572884811416922e-05,
      "loss": 0.0525,
      "step": 420
    },
    {
      "epoch": 0.6574923547400612,
      "grad_norm": 0.4791237413883209,
      "learning_rate": 1.5626911314984713e-05,
      "loss": 0.0349,
      "step": 430
    },
    {
      "epoch": 0.672782874617737,
      "grad_norm": 0.337268203496933,
      "learning_rate": 1.5524974515800205e-05,
      "loss": 0.0244,
      "step": 440
    },
    {
      "epoch": 0.6880733944954128,
      "grad_norm": 0.7171729803085327,
      "learning_rate": 1.54230377166157e-05,
      "loss": 0.0192,
      "step": 450
    },
    {
      "epoch": 0.7033639143730887,
      "grad_norm": 0.24195055663585663,
      "learning_rate": 1.5321100917431192e-05,
      "loss": 0.0151,
      "step": 460
    },
    {
      "epoch": 0.7186544342507645,
      "grad_norm": 0.22292931377887726,
      "learning_rate": 1.5219164118246687e-05,
      "loss": 0.0126,
      "step": 470
    },
    {
      "epoch": 0.7339449541284404,
      "grad_norm": 0.20235422253608704,
      "learning_rate": 1.5117227319062182e-05,
      "loss": 0.01,
      "step": 480
    },
    {
      "epoch": 0.7492354740061162,
      "grad_norm": 0.18060870468616486,
      "learning_rate": 1.5015290519877677e-05,
      "loss": 0.0092,
      "step": 490
    },
    {
      "epoch": 0.764525993883792,
      "grad_norm": 0.16068263351917267,
      "learning_rate": 1.491335372069317e-05,
      "loss": 0.007,
      "step": 500
    },
    {
      "epoch": 0.7798165137614679,
      "grad_norm": 0.13932248950004578,
      "learning_rate": 1.4811416921508665e-05,
      "loss": 0.0055,
      "step": 510
    },
    {
      "epoch": 0.7951070336391437,
      "grad_norm": 0.11116492003202438,
      "learning_rate": 1.470948012232416e-05,
      "loss": 0.0047,
      "step": 520
    },
    {
      "epoch": 0.8103975535168195,
      "grad_norm": 0.11900023370981216,
      "learning_rate": 1.4607543323139655e-05,
      "loss": 0.0038,
      "step": 530
    },
    {
      "epoch": 0.8256880733944955,
      "grad_norm": 0.08618087321519852,
      "learning_rate": 1.4505606523955149e-05,
      "loss": 0.0033,
      "step": 540
    },
    {
      "epoch": 0.8409785932721713,
      "grad_norm": 0.08319692313671112,
      "learning_rate": 1.4403669724770644e-05,
      "loss": 0.0036,
      "step": 550
    },
    {
      "epoch": 0.8562691131498471,
      "grad_norm": 0.07178600877523422,
      "learning_rate": 1.4301732925586139e-05,
      "loss": 0.0025,
      "step": 560
    },
    {
      "epoch": 0.8715596330275229,
      "grad_norm": 0.060127392411231995,
      "learning_rate": 1.4199796126401632e-05,
      "loss": 0.0024,
      "step": 570
    },
    {
      "epoch": 0.8868501529051988,
      "grad_norm": 0.0678093209862709,
      "learning_rate": 1.4097859327217127e-05,
      "loss": 0.0022,
      "step": 580
    },
    {
      "epoch": 0.9021406727828746,
      "grad_norm": 0.05049557238817215,
      "learning_rate": 1.3995922528032622e-05,
      "loss": 0.002,
      "step": 590
    },
    {
      "epoch": 0.9174311926605505,
      "grad_norm": 0.05127404257655144,
      "learning_rate": 1.3893985728848116e-05,
      "loss": 0.0018,
      "step": 600
    },
    {
      "epoch": 0.9327217125382263,
      "grad_norm": 0.04587528854608536,
      "learning_rate": 1.379204892966361e-05,
      "loss": 0.0016,
      "step": 610
    },
    {
      "epoch": 0.9480122324159022,
      "grad_norm": 0.043915510177612305,
      "learning_rate": 1.3690112130479106e-05,
      "loss": 0.0015,
      "step": 620
    },
    {
      "epoch": 0.963302752293578,
      "grad_norm": 0.04058119282126427,
      "learning_rate": 1.3588175331294597e-05,
      "loss": 0.0015,
      "step": 630
    },
    {
      "epoch": 0.9785932721712538,
      "grad_norm": 0.040871698409318924,
      "learning_rate": 1.3486238532110092e-05,
      "loss": 0.0013,
      "step": 640
    },
    {
      "epoch": 0.9938837920489296,
      "grad_norm": 6.0444111824035645,
      "learning_rate": 1.3384301732925586e-05,
      "loss": 0.0041,
      "step": 650
    }
  ],
  "logging_steps": 10,
  "max_steps": 1962,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1040344726634496.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
