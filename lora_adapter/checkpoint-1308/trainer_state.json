{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 1308,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01529051987767584,
      "grad_norm": 11.022989273071289,
      "learning_rate": 1.9908256880733945e-05,
      "loss": 12.0231,
      "step": 10
    },
    {
      "epoch": 0.03058103975535168,
      "grad_norm": 155.26002502441406,
      "learning_rate": 1.980632008154944e-05,
      "loss": 13.7919,
      "step": 20
    },
    {
      "epoch": 0.045871559633027525,
      "grad_norm": 8.996129035949707,
      "learning_rate": 1.9704383282364936e-05,
      "loss": 13.1686,
      "step": 30
    },
    {
      "epoch": 0.06116207951070336,
      "grad_norm": 141.7963104248047,
      "learning_rate": 1.960244648318043e-05,
      "loss": 13.3416,
      "step": 40
    },
    {
      "epoch": 0.0764525993883792,
      "grad_norm": 44.24433517456055,
      "learning_rate": 1.9500509683995926e-05,
      "loss": 13.182,
      "step": 50
    },
    {
      "epoch": 0.09174311926605505,
      "grad_norm": 13.48249340057373,
      "learning_rate": 1.9398572884811417e-05,
      "loss": 13.0575,
      "step": 60
    },
    {
      "epoch": 0.10703363914373089,
      "grad_norm": 88.3427505493164,
      "learning_rate": 1.9296636085626912e-05,
      "loss": 12.4913,
      "step": 70
    },
    {
      "epoch": 0.12232415902140673,
      "grad_norm": 172.0810546875,
      "learning_rate": 1.9194699286442407e-05,
      "loss": 11.2284,
      "step": 80
    },
    {
      "epoch": 0.13761467889908258,
      "grad_norm": 149.57150268554688,
      "learning_rate": 1.9092762487257902e-05,
      "loss": 11.1828,
      "step": 90
    },
    {
      "epoch": 0.1529051987767584,
      "grad_norm": 16.117151260375977,
      "learning_rate": 1.8990825688073394e-05,
      "loss": 10.2954,
      "step": 100
    },
    {
      "epoch": 0.16819571865443425,
      "grad_norm": 20.483734130859375,
      "learning_rate": 1.888888888888889e-05,
      "loss": 9.0832,
      "step": 110
    },
    {
      "epoch": 0.1834862385321101,
      "grad_norm": 26.03529167175293,
      "learning_rate": 1.8786952089704384e-05,
      "loss": 9.9902,
      "step": 120
    },
    {
      "epoch": 0.19877675840978593,
      "grad_norm": 51.66054916381836,
      "learning_rate": 1.868501529051988e-05,
      "loss": 8.1638,
      "step": 130
    },
    {
      "epoch": 0.21406727828746178,
      "grad_norm": 163.2643280029297,
      "learning_rate": 1.8583078491335374e-05,
      "loss": 8.1312,
      "step": 140
    },
    {
      "epoch": 0.22935779816513763,
      "grad_norm": 52.623809814453125,
      "learning_rate": 1.848114169215087e-05,
      "loss": 7.9207,
      "step": 150
    },
    {
      "epoch": 0.24464831804281345,
      "grad_norm": 32.053035736083984,
      "learning_rate": 1.837920489296636e-05,
      "loss": 6.3753,
      "step": 160
    },
    {
      "epoch": 0.2599388379204893,
      "grad_norm": 79.20103454589844,
      "learning_rate": 1.8277268093781856e-05,
      "loss": 5.6334,
      "step": 170
    },
    {
      "epoch": 0.27522935779816515,
      "grad_norm": 27.640329360961914,
      "learning_rate": 1.817533129459735e-05,
      "loss": 4.9015,
      "step": 180
    },
    {
      "epoch": 0.290519877675841,
      "grad_norm": 27.43526268005371,
      "learning_rate": 1.8073394495412846e-05,
      "loss": 4.2102,
      "step": 190
    },
    {
      "epoch": 0.3058103975535168,
      "grad_norm": 17.84138298034668,
      "learning_rate": 1.797145769622834e-05,
      "loss": 4.2758,
      "step": 200
    },
    {
      "epoch": 0.3211009174311927,
      "grad_norm": 17.423583984375,
      "learning_rate": 1.7869520897043836e-05,
      "loss": 4.203,
      "step": 210
    },
    {
      "epoch": 0.3363914373088685,
      "grad_norm": 14.66960334777832,
      "learning_rate": 1.7767584097859328e-05,
      "loss": 2.4859,
      "step": 220
    },
    {
      "epoch": 0.3516819571865443,
      "grad_norm": 17.27591896057129,
      "learning_rate": 1.7665647298674823e-05,
      "loss": 2.6796,
      "step": 230
    },
    {
      "epoch": 0.3669724770642202,
      "grad_norm": 10.101943016052246,
      "learning_rate": 1.7563710499490318e-05,
      "loss": 2.3312,
      "step": 240
    },
    {
      "epoch": 0.382262996941896,
      "grad_norm": 14.564958572387695,
      "learning_rate": 1.746177370030581e-05,
      "loss": 1.9515,
      "step": 250
    },
    {
      "epoch": 0.39755351681957185,
      "grad_norm": 3.7078545093536377,
      "learning_rate": 1.7359836901121305e-05,
      "loss": 1.8833,
      "step": 260
    },
    {
      "epoch": 0.41284403669724773,
      "grad_norm": 3.6452858448028564,
      "learning_rate": 1.72579001019368e-05,
      "loss": 1.0571,
      "step": 270
    },
    {
      "epoch": 0.42813455657492355,
      "grad_norm": 2.051708221435547,
      "learning_rate": 1.7155963302752295e-05,
      "loss": 0.5912,
      "step": 280
    },
    {
      "epoch": 0.4434250764525994,
      "grad_norm": 1.3715555667877197,
      "learning_rate": 1.705402650356779e-05,
      "loss": 0.5931,
      "step": 290
    },
    {
      "epoch": 0.45871559633027525,
      "grad_norm": 0.9812724590301514,
      "learning_rate": 1.6952089704383285e-05,
      "loss": 0.5488,
      "step": 300
    },
    {
      "epoch": 0.4740061162079511,
      "grad_norm": 0.8181449770927429,
      "learning_rate": 1.6850152905198776e-05,
      "loss": 0.4319,
      "step": 310
    },
    {
      "epoch": 0.4892966360856269,
      "grad_norm": 0.8397002816200256,
      "learning_rate": 1.674821610601427e-05,
      "loss": 0.3806,
      "step": 320
    },
    {
      "epoch": 0.5045871559633027,
      "grad_norm": 0.7191246747970581,
      "learning_rate": 1.6646279306829766e-05,
      "loss": 0.3467,
      "step": 330
    },
    {
      "epoch": 0.5198776758409785,
      "grad_norm": 0.7541691064834595,
      "learning_rate": 1.654434250764526e-05,
      "loss": 0.315,
      "step": 340
    },
    {
      "epoch": 0.5351681957186545,
      "grad_norm": 0.7385095953941345,
      "learning_rate": 1.6442405708460757e-05,
      "loss": 0.3024,
      "step": 350
    },
    {
      "epoch": 0.5504587155963303,
      "grad_norm": 0.7344053387641907,
      "learning_rate": 1.634046890927625e-05,
      "loss": 0.2487,
      "step": 360
    },
    {
      "epoch": 0.5657492354740061,
      "grad_norm": 0.7197365164756775,
      "learning_rate": 1.6238532110091743e-05,
      "loss": 0.214,
      "step": 370
    },
    {
      "epoch": 0.581039755351682,
      "grad_norm": 0.7380478382110596,
      "learning_rate": 1.6136595310907238e-05,
      "loss": 0.1807,
      "step": 380
    },
    {
      "epoch": 0.5963302752293578,
      "grad_norm": 0.7074641585350037,
      "learning_rate": 1.6034658511722733e-05,
      "loss": 0.1453,
      "step": 390
    },
    {
      "epoch": 0.6116207951070336,
      "grad_norm": 1.5917141437530518,
      "learning_rate": 1.593272171253823e-05,
      "loss": 0.1116,
      "step": 400
    },
    {
      "epoch": 0.6269113149847095,
      "grad_norm": 0.6585666537284851,
      "learning_rate": 1.5830784913353723e-05,
      "loss": 0.0789,
      "step": 410
    },
    {
      "epoch": 0.6422018348623854,
      "grad_norm": 0.5678913593292236,
      "learning_rate": 1.572884811416922e-05,
      "loss": 0.0525,
      "step": 420
    },
    {
      "epoch": 0.6574923547400612,
      "grad_norm": 0.4791237413883209,
      "learning_rate": 1.5626911314984713e-05,
      "loss": 0.0349,
      "step": 430
    },
    {
      "epoch": 0.672782874617737,
      "grad_norm": 0.337268203496933,
      "learning_rate": 1.5524974515800205e-05,
      "loss": 0.0244,
      "step": 440
    },
    {
      "epoch": 0.6880733944954128,
      "grad_norm": 0.7171729803085327,
      "learning_rate": 1.54230377166157e-05,
      "loss": 0.0192,
      "step": 450
    },
    {
      "epoch": 0.7033639143730887,
      "grad_norm": 0.24195055663585663,
      "learning_rate": 1.5321100917431192e-05,
      "loss": 0.0151,
      "step": 460
    },
    {
      "epoch": 0.7186544342507645,
      "grad_norm": 0.22292931377887726,
      "learning_rate": 1.5219164118246687e-05,
      "loss": 0.0126,
      "step": 470
    },
    {
      "epoch": 0.7339449541284404,
      "grad_norm": 0.20235422253608704,
      "learning_rate": 1.5117227319062182e-05,
      "loss": 0.01,
      "step": 480
    },
    {
      "epoch": 0.7492354740061162,
      "grad_norm": 0.18060870468616486,
      "learning_rate": 1.5015290519877677e-05,
      "loss": 0.0092,
      "step": 490
    },
    {
      "epoch": 0.764525993883792,
      "grad_norm": 0.16068263351917267,
      "learning_rate": 1.491335372069317e-05,
      "loss": 0.007,
      "step": 500
    },
    {
      "epoch": 0.7798165137614679,
      "grad_norm": 0.13932248950004578,
      "learning_rate": 1.4811416921508665e-05,
      "loss": 0.0055,
      "step": 510
    },
    {
      "epoch": 0.7951070336391437,
      "grad_norm": 0.11116492003202438,
      "learning_rate": 1.470948012232416e-05,
      "loss": 0.0047,
      "step": 520
    },
    {
      "epoch": 0.8103975535168195,
      "grad_norm": 0.11900023370981216,
      "learning_rate": 1.4607543323139655e-05,
      "loss": 0.0038,
      "step": 530
    },
    {
      "epoch": 0.8256880733944955,
      "grad_norm": 0.08618087321519852,
      "learning_rate": 1.4505606523955149e-05,
      "loss": 0.0033,
      "step": 540
    },
    {
      "epoch": 0.8409785932721713,
      "grad_norm": 0.08319692313671112,
      "learning_rate": 1.4403669724770644e-05,
      "loss": 0.0036,
      "step": 550
    },
    {
      "epoch": 0.8562691131498471,
      "grad_norm": 0.07178600877523422,
      "learning_rate": 1.4301732925586139e-05,
      "loss": 0.0025,
      "step": 560
    },
    {
      "epoch": 0.8715596330275229,
      "grad_norm": 0.060127392411231995,
      "learning_rate": 1.4199796126401632e-05,
      "loss": 0.0024,
      "step": 570
    },
    {
      "epoch": 0.8868501529051988,
      "grad_norm": 0.0678093209862709,
      "learning_rate": 1.4097859327217127e-05,
      "loss": 0.0022,
      "step": 580
    },
    {
      "epoch": 0.9021406727828746,
      "grad_norm": 0.05049557238817215,
      "learning_rate": 1.3995922528032622e-05,
      "loss": 0.002,
      "step": 590
    },
    {
      "epoch": 0.9174311926605505,
      "grad_norm": 0.05127404257655144,
      "learning_rate": 1.3893985728848116e-05,
      "loss": 0.0018,
      "step": 600
    },
    {
      "epoch": 0.9327217125382263,
      "grad_norm": 0.04587528854608536,
      "learning_rate": 1.379204892966361e-05,
      "loss": 0.0016,
      "step": 610
    },
    {
      "epoch": 0.9480122324159022,
      "grad_norm": 0.043915510177612305,
      "learning_rate": 1.3690112130479106e-05,
      "loss": 0.0015,
      "step": 620
    },
    {
      "epoch": 0.963302752293578,
      "grad_norm": 0.04058119282126427,
      "learning_rate": 1.3588175331294597e-05,
      "loss": 0.0015,
      "step": 630
    },
    {
      "epoch": 0.9785932721712538,
      "grad_norm": 0.040871698409318924,
      "learning_rate": 1.3486238532110092e-05,
      "loss": 0.0013,
      "step": 640
    },
    {
      "epoch": 0.9938837920489296,
      "grad_norm": 6.0444111824035645,
      "learning_rate": 1.3384301732925586e-05,
      "loss": 0.0041,
      "step": 650
    },
    {
      "epoch": 1.0091743119266054,
      "grad_norm": 0.0319955050945282,
      "learning_rate": 1.328236493374108e-05,
      "loss": 0.0012,
      "step": 660
    },
    {
      "epoch": 1.0244648318042813,
      "grad_norm": 0.03555909916758537,
      "learning_rate": 1.3180428134556576e-05,
      "loss": 0.0011,
      "step": 670
    },
    {
      "epoch": 1.039755351681957,
      "grad_norm": 0.030057964846491814,
      "learning_rate": 1.307849133537207e-05,
      "loss": 0.0011,
      "step": 680
    },
    {
      "epoch": 1.0550458715596331,
      "grad_norm": 0.02930895984172821,
      "learning_rate": 1.2976554536187564e-05,
      "loss": 0.0011,
      "step": 690
    },
    {
      "epoch": 1.070336391437309,
      "grad_norm": 0.027481280267238617,
      "learning_rate": 1.287461773700306e-05,
      "loss": 0.001,
      "step": 700
    },
    {
      "epoch": 1.0856269113149848,
      "grad_norm": 0.025659389793872833,
      "learning_rate": 1.2772680937818553e-05,
      "loss": 0.001,
      "step": 710
    },
    {
      "epoch": 1.1009174311926606,
      "grad_norm": 0.023793024942278862,
      "learning_rate": 1.2670744138634048e-05,
      "loss": 0.0009,
      "step": 720
    },
    {
      "epoch": 1.1162079510703364,
      "grad_norm": 0.023502003401517868,
      "learning_rate": 1.2568807339449543e-05,
      "loss": 0.0009,
      "step": 730
    },
    {
      "epoch": 1.1314984709480123,
      "grad_norm": 0.029705986380577087,
      "learning_rate": 1.2466870540265038e-05,
      "loss": 0.0009,
      "step": 740
    },
    {
      "epoch": 1.146788990825688,
      "grad_norm": 0.021893218159675598,
      "learning_rate": 1.2364933741080531e-05,
      "loss": 0.0009,
      "step": 750
    },
    {
      "epoch": 1.162079510703364,
      "grad_norm": 0.02114271931350231,
      "learning_rate": 1.2262996941896026e-05,
      "loss": 0.0008,
      "step": 760
    },
    {
      "epoch": 1.1773700305810397,
      "grad_norm": 0.02491748332977295,
      "learning_rate": 1.2161060142711521e-05,
      "loss": 0.0008,
      "step": 770
    },
    {
      "epoch": 1.1926605504587156,
      "grad_norm": 0.023754911497235298,
      "learning_rate": 1.2059123343527015e-05,
      "loss": 0.0007,
      "step": 780
    },
    {
      "epoch": 1.2079510703363914,
      "grad_norm": 0.01951880380511284,
      "learning_rate": 1.195718654434251e-05,
      "loss": 0.0007,
      "step": 790
    },
    {
      "epoch": 1.2232415902140672,
      "grad_norm": 0.01987084187567234,
      "learning_rate": 1.1855249745158005e-05,
      "loss": 0.0007,
      "step": 800
    },
    {
      "epoch": 1.238532110091743,
      "grad_norm": 0.0195015836507082,
      "learning_rate": 1.1753312945973498e-05,
      "loss": 0.0007,
      "step": 810
    },
    {
      "epoch": 1.2538226299694188,
      "grad_norm": 0.017946472391486168,
      "learning_rate": 1.1651376146788991e-05,
      "loss": 0.0006,
      "step": 820
    },
    {
      "epoch": 1.2691131498470947,
      "grad_norm": 0.018603157252073288,
      "learning_rate": 1.1549439347604485e-05,
      "loss": 0.0006,
      "step": 830
    },
    {
      "epoch": 1.2844036697247707,
      "grad_norm": 0.016581816598773003,
      "learning_rate": 1.144750254841998e-05,
      "loss": 0.0006,
      "step": 840
    },
    {
      "epoch": 1.2996941896024465,
      "grad_norm": 0.015787791460752487,
      "learning_rate": 1.1345565749235475e-05,
      "loss": 0.0006,
      "step": 850
    },
    {
      "epoch": 1.3149847094801224,
      "grad_norm": 0.021128060296177864,
      "learning_rate": 1.1243628950050968e-05,
      "loss": 0.0006,
      "step": 860
    },
    {
      "epoch": 1.3302752293577982,
      "grad_norm": 0.029093297198414803,
      "learning_rate": 1.1141692150866463e-05,
      "loss": 0.0006,
      "step": 870
    },
    {
      "epoch": 1.345565749235474,
      "grad_norm": 0.014009644277393818,
      "learning_rate": 1.1039755351681958e-05,
      "loss": 0.0005,
      "step": 880
    },
    {
      "epoch": 1.3608562691131498,
      "grad_norm": 0.014151031151413918,
      "learning_rate": 1.0937818552497452e-05,
      "loss": 0.0006,
      "step": 890
    },
    {
      "epoch": 1.3761467889908257,
      "grad_norm": 0.026300912722945213,
      "learning_rate": 1.0835881753312947e-05,
      "loss": 0.0005,
      "step": 900
    },
    {
      "epoch": 1.3914373088685015,
      "grad_norm": 0.02053004503250122,
      "learning_rate": 1.0733944954128442e-05,
      "loss": 0.0005,
      "step": 910
    },
    {
      "epoch": 1.4067278287461773,
      "grad_norm": 0.013330142945051193,
      "learning_rate": 1.0632008154943935e-05,
      "loss": 0.0005,
      "step": 920
    },
    {
      "epoch": 1.4220183486238533,
      "grad_norm": 0.01429784670472145,
      "learning_rate": 1.053007135575943e-05,
      "loss": 0.0005,
      "step": 930
    },
    {
      "epoch": 1.4373088685015292,
      "grad_norm": 0.012813059613108635,
      "learning_rate": 1.0428134556574925e-05,
      "loss": 0.0005,
      "step": 940
    },
    {
      "epoch": 1.452599388379205,
      "grad_norm": 0.012756419368088245,
      "learning_rate": 1.032619775739042e-05,
      "loss": 0.0008,
      "step": 950
    },
    {
      "epoch": 1.4678899082568808,
      "grad_norm": 0.03186206892132759,
      "learning_rate": 1.0224260958205913e-05,
      "loss": 0.0005,
      "step": 960
    },
    {
      "epoch": 1.4831804281345566,
      "grad_norm": 0.013465682044625282,
      "learning_rate": 1.0122324159021408e-05,
      "loss": 0.0004,
      "step": 970
    },
    {
      "epoch": 1.4984709480122325,
      "grad_norm": 0.013659958727657795,
      "learning_rate": 1.0020387359836904e-05,
      "loss": 0.0004,
      "step": 980
    },
    {
      "epoch": 1.5137614678899083,
      "grad_norm": 0.01184915192425251,
      "learning_rate": 9.918450560652397e-06,
      "loss": 0.0045,
      "step": 990
    },
    {
      "epoch": 1.529051987767584,
      "grad_norm": 0.01341851707547903,
      "learning_rate": 9.81651376146789e-06,
      "loss": 0.0004,
      "step": 1000
    },
    {
      "epoch": 1.54434250764526,
      "grad_norm": 0.012447740882635117,
      "learning_rate": 9.714576962283385e-06,
      "loss": 0.0004,
      "step": 1010
    },
    {
      "epoch": 1.5596330275229358,
      "grad_norm": 0.014241088181734085,
      "learning_rate": 9.61264016309888e-06,
      "loss": 0.0004,
      "step": 1020
    },
    {
      "epoch": 1.5749235474006116,
      "grad_norm": 0.015965444967150688,
      "learning_rate": 9.510703363914374e-06,
      "loss": 0.0004,
      "step": 1030
    },
    {
      "epoch": 1.5902140672782874,
      "grad_norm": 0.011438843794167042,
      "learning_rate": 9.408766564729869e-06,
      "loss": 0.0004,
      "step": 1040
    },
    {
      "epoch": 1.6055045871559632,
      "grad_norm": 0.013023270294070244,
      "learning_rate": 9.306829765545362e-06,
      "loss": 0.0004,
      "step": 1050
    },
    {
      "epoch": 1.620795107033639,
      "grad_norm": 0.01416064240038395,
      "learning_rate": 9.204892966360857e-06,
      "loss": 0.0004,
      "step": 1060
    },
    {
      "epoch": 1.6360856269113149,
      "grad_norm": 0.01107722893357277,
      "learning_rate": 9.10295616717635e-06,
      "loss": 0.0004,
      "step": 1070
    },
    {
      "epoch": 1.6513761467889907,
      "grad_norm": 0.010181847028434277,
      "learning_rate": 9.001019367991845e-06,
      "loss": 0.0004,
      "step": 1080
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 0.011222156696021557,
      "learning_rate": 8.89908256880734e-06,
      "loss": 0.0004,
      "step": 1090
    },
    {
      "epoch": 1.6819571865443423,
      "grad_norm": 0.011280720122158527,
      "learning_rate": 8.797145769622834e-06,
      "loss": 0.0004,
      "step": 1100
    },
    {
      "epoch": 1.6972477064220184,
      "grad_norm": 0.010504381731152534,
      "learning_rate": 8.695208970438329e-06,
      "loss": 0.0004,
      "step": 1110
    },
    {
      "epoch": 1.7125382262996942,
      "grad_norm": 0.010950583033263683,
      "learning_rate": 8.593272171253824e-06,
      "loss": 0.0004,
      "step": 1120
    },
    {
      "epoch": 1.72782874617737,
      "grad_norm": 0.012429505586624146,
      "learning_rate": 8.491335372069319e-06,
      "loss": 0.0003,
      "step": 1130
    },
    {
      "epoch": 1.7431192660550459,
      "grad_norm": 0.012413672171533108,
      "learning_rate": 8.389398572884812e-06,
      "loss": 0.0003,
      "step": 1140
    },
    {
      "epoch": 1.7584097859327217,
      "grad_norm": 0.009762225672602654,
      "learning_rate": 8.287461773700306e-06,
      "loss": 0.0003,
      "step": 1150
    },
    {
      "epoch": 1.7737003058103975,
      "grad_norm": 0.024060431867837906,
      "learning_rate": 8.1855249745158e-06,
      "loss": 0.0003,
      "step": 1160
    },
    {
      "epoch": 1.7889908256880735,
      "grad_norm": 0.013152371160686016,
      "learning_rate": 8.083588175331296e-06,
      "loss": 0.0003,
      "step": 1170
    },
    {
      "epoch": 1.8042813455657494,
      "grad_norm": 0.008623664267361164,
      "learning_rate": 7.981651376146789e-06,
      "loss": 0.0003,
      "step": 1180
    },
    {
      "epoch": 1.8195718654434252,
      "grad_norm": 0.008839460089802742,
      "learning_rate": 7.879714576962284e-06,
      "loss": 0.0003,
      "step": 1190
    },
    {
      "epoch": 1.834862385321101,
      "grad_norm": 0.011806725524365902,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.0003,
      "step": 1200
    },
    {
      "epoch": 1.8501529051987768,
      "grad_norm": 0.010293346829712391,
      "learning_rate": 7.675840978593273e-06,
      "loss": 0.0003,
      "step": 1210
    },
    {
      "epoch": 1.8654434250764527,
      "grad_norm": 0.00845242664217949,
      "learning_rate": 7.5739041794087676e-06,
      "loss": 0.0003,
      "step": 1220
    },
    {
      "epoch": 1.8807339449541285,
      "grad_norm": 0.008457960560917854,
      "learning_rate": 7.471967380224262e-06,
      "loss": 0.0003,
      "step": 1230
    },
    {
      "epoch": 1.8960244648318043,
      "grad_norm": 0.008671374060213566,
      "learning_rate": 7.370030581039755e-06,
      "loss": 0.0003,
      "step": 1240
    },
    {
      "epoch": 1.9113149847094801,
      "grad_norm": 0.008446973748505116,
      "learning_rate": 7.26809378185525e-06,
      "loss": 0.0003,
      "step": 1250
    },
    {
      "epoch": 1.926605504587156,
      "grad_norm": 0.008769064210355282,
      "learning_rate": 7.166156982670744e-06,
      "loss": 0.0003,
      "step": 1260
    },
    {
      "epoch": 1.9418960244648318,
      "grad_norm": 0.007957087829709053,
      "learning_rate": 7.0642201834862385e-06,
      "loss": 0.0003,
      "step": 1270
    },
    {
      "epoch": 1.9571865443425076,
      "grad_norm": 0.010166460648179054,
      "learning_rate": 6.9622833843017336e-06,
      "loss": 0.0003,
      "step": 1280
    },
    {
      "epoch": 1.9724770642201834,
      "grad_norm": 0.00764585193246603,
      "learning_rate": 6.860346585117228e-06,
      "loss": 0.0003,
      "step": 1290
    },
    {
      "epoch": 1.9877675840978593,
      "grad_norm": 0.007096851244568825,
      "learning_rate": 6.758409785932723e-06,
      "loss": 0.0003,
      "step": 1300
    }
  ],
  "logging_steps": 10,
  "max_steps": 1962,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2080689453268992.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
