{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.337807606263982,
  "eval_steps": 500,
  "global_step": 598,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02237136465324385,
      "grad_norm": 29.578956604003906,
      "learning_rate": 1.986577181208054e-05,
      "loss": 13.2164,
      "step": 10
    },
    {
      "epoch": 0.0447427293064877,
      "grad_norm": 33.79019546508789,
      "learning_rate": 1.9716629381058913e-05,
      "loss": 13.6946,
      "step": 20
    },
    {
      "epoch": 0.06711409395973154,
      "grad_norm": 9.988222122192383,
      "learning_rate": 1.9567486950037287e-05,
      "loss": 13.2379,
      "step": 30
    },
    {
      "epoch": 0.0894854586129754,
      "grad_norm": 43.14265823364258,
      "learning_rate": 1.941834451901566e-05,
      "loss": 13.4136,
      "step": 40
    },
    {
      "epoch": 0.11185682326621924,
      "grad_norm": 47.47526931762695,
      "learning_rate": 1.9269202087994035e-05,
      "loss": 12.9663,
      "step": 50
    },
    {
      "epoch": 0.1342281879194631,
      "grad_norm": 16.55957794189453,
      "learning_rate": 1.912005965697241e-05,
      "loss": 12.0796,
      "step": 60
    },
    {
      "epoch": 0.15659955257270694,
      "grad_norm": 41.002864837646484,
      "learning_rate": 1.8970917225950784e-05,
      "loss": 11.8359,
      "step": 70
    },
    {
      "epoch": 0.1789709172259508,
      "grad_norm": 19.50739860534668,
      "learning_rate": 1.882177479492916e-05,
      "loss": 11.7764,
      "step": 80
    },
    {
      "epoch": 0.20134228187919462,
      "grad_norm": 21.717144012451172,
      "learning_rate": 1.8672632363907532e-05,
      "loss": 11.5766,
      "step": 90
    },
    {
      "epoch": 0.22371364653243847,
      "grad_norm": 19.86582374572754,
      "learning_rate": 1.8523489932885906e-05,
      "loss": 9.4895,
      "step": 100
    },
    {
      "epoch": 0.24608501118568232,
      "grad_norm": 88.40103912353516,
      "learning_rate": 1.8374347501864283e-05,
      "loss": 8.9258,
      "step": 110
    },
    {
      "epoch": 0.2684563758389262,
      "grad_norm": 89.03437805175781,
      "learning_rate": 1.8225205070842654e-05,
      "loss": 9.396,
      "step": 120
    },
    {
      "epoch": 0.29082774049217003,
      "grad_norm": 68.8408203125,
      "learning_rate": 1.8076062639821032e-05,
      "loss": 9.3091,
      "step": 130
    },
    {
      "epoch": 0.3131991051454139,
      "grad_norm": 30.819002151489258,
      "learning_rate": 1.7926920208799406e-05,
      "loss": 7.8645,
      "step": 140
    },
    {
      "epoch": 0.33557046979865773,
      "grad_norm": 26.761566162109375,
      "learning_rate": 1.7777777777777777e-05,
      "loss": 7.1237,
      "step": 150
    },
    {
      "epoch": 0.3579418344519016,
      "grad_norm": 65.63278198242188,
      "learning_rate": 1.7628635346756154e-05,
      "loss": 6.0858,
      "step": 160
    },
    {
      "epoch": 0.38031319910514544,
      "grad_norm": 26.31956672668457,
      "learning_rate": 1.7479492915734528e-05,
      "loss": 5.3758,
      "step": 170
    },
    {
      "epoch": 0.40268456375838924,
      "grad_norm": 83.39583587646484,
      "learning_rate": 1.7330350484712902e-05,
      "loss": 5.2379,
      "step": 180
    },
    {
      "epoch": 0.4250559284116331,
      "grad_norm": 27.97832679748535,
      "learning_rate": 1.7181208053691277e-05,
      "loss": 4.0904,
      "step": 190
    },
    {
      "epoch": 0.44742729306487694,
      "grad_norm": 17.955387115478516,
      "learning_rate": 1.703206562266965e-05,
      "loss": 4.2141,
      "step": 200
    },
    {
      "epoch": 0.4697986577181208,
      "grad_norm": 45.447265625,
      "learning_rate": 1.6882923191648025e-05,
      "loss": 3.307,
      "step": 210
    },
    {
      "epoch": 0.49217002237136465,
      "grad_norm": 23.993173599243164,
      "learning_rate": 1.67337807606264e-05,
      "loss": 2.7431,
      "step": 220
    },
    {
      "epoch": 0.5145413870246085,
      "grad_norm": 13.532779693603516,
      "learning_rate": 1.6584638329604773e-05,
      "loss": 2.7487,
      "step": 230
    },
    {
      "epoch": 0.5369127516778524,
      "grad_norm": 13.469728469848633,
      "learning_rate": 1.643549589858315e-05,
      "loss": 2.0368,
      "step": 240
    },
    {
      "epoch": 0.5592841163310962,
      "grad_norm": 14.79787826538086,
      "learning_rate": 1.628635346756152e-05,
      "loss": 1.96,
      "step": 250
    },
    {
      "epoch": 0.5816554809843401,
      "grad_norm": 14.563250541687012,
      "learning_rate": 1.6137211036539895e-05,
      "loss": 1.014,
      "step": 260
    },
    {
      "epoch": 0.6040268456375839,
      "grad_norm": 6.102721691131592,
      "learning_rate": 1.5988068605518273e-05,
      "loss": 0.6967,
      "step": 270
    },
    {
      "epoch": 0.6263982102908278,
      "grad_norm": 1.6875314712524414,
      "learning_rate": 1.5838926174496644e-05,
      "loss": 0.6043,
      "step": 280
    },
    {
      "epoch": 0.6487695749440716,
      "grad_norm": 0.8114166855812073,
      "learning_rate": 1.568978374347502e-05,
      "loss": 0.5189,
      "step": 290
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 2.054011583328247,
      "learning_rate": 1.5540641312453395e-05,
      "loss": 0.4558,
      "step": 300
    },
    {
      "epoch": 0.6935123042505593,
      "grad_norm": 0.6711454391479492,
      "learning_rate": 1.5391498881431766e-05,
      "loss": 0.4151,
      "step": 310
    },
    {
      "epoch": 0.7158836689038032,
      "grad_norm": 0.6891064047813416,
      "learning_rate": 1.5242356450410144e-05,
      "loss": 0.3983,
      "step": 320
    },
    {
      "epoch": 0.738255033557047,
      "grad_norm": 0.7690008282661438,
      "learning_rate": 1.5093214019388518e-05,
      "loss": 0.3619,
      "step": 330
    },
    {
      "epoch": 0.7606263982102909,
      "grad_norm": 0.7296878695487976,
      "learning_rate": 1.494407158836689e-05,
      "loss": 0.3339,
      "step": 340
    },
    {
      "epoch": 0.7829977628635347,
      "grad_norm": 1.375214695930481,
      "learning_rate": 1.4794929157345266e-05,
      "loss": 0.3047,
      "step": 350
    },
    {
      "epoch": 0.8053691275167785,
      "grad_norm": 0.7826278805732727,
      "learning_rate": 1.464578672632364e-05,
      "loss": 0.2725,
      "step": 360
    },
    {
      "epoch": 0.8277404921700223,
      "grad_norm": 0.7869710922241211,
      "learning_rate": 1.4496644295302014e-05,
      "loss": 0.2528,
      "step": 370
    },
    {
      "epoch": 0.8501118568232662,
      "grad_norm": 0.7275776267051697,
      "learning_rate": 1.4347501864280388e-05,
      "loss": 0.2071,
      "step": 380
    },
    {
      "epoch": 0.87248322147651,
      "grad_norm": 0.6897491216659546,
      "learning_rate": 1.4198359433258764e-05,
      "loss": 0.1758,
      "step": 390
    },
    {
      "epoch": 0.8948545861297539,
      "grad_norm": 0.650148332118988,
      "learning_rate": 1.4049217002237137e-05,
      "loss": 0.1474,
      "step": 400
    },
    {
      "epoch": 0.9172259507829977,
      "grad_norm": 1.2712868452072144,
      "learning_rate": 1.3900074571215511e-05,
      "loss": 0.1222,
      "step": 410
    },
    {
      "epoch": 0.9395973154362416,
      "grad_norm": 1.0473171472549438,
      "learning_rate": 1.3750932140193887e-05,
      "loss": 0.0986,
      "step": 420
    },
    {
      "epoch": 0.9619686800894854,
      "grad_norm": 0.49405330419540405,
      "learning_rate": 1.3601789709172261e-05,
      "loss": 0.0786,
      "step": 430
    },
    {
      "epoch": 0.9843400447427293,
      "grad_norm": 0.6507055759429932,
      "learning_rate": 1.3452647278150635e-05,
      "loss": 0.0632,
      "step": 440
    },
    {
      "epoch": 1.0067114093959733,
      "grad_norm": 0.30905821919441223,
      "learning_rate": 1.3303504847129009e-05,
      "loss": 0.0523,
      "step": 450
    },
    {
      "epoch": 1.029082774049217,
      "grad_norm": 0.6258965134620667,
      "learning_rate": 1.3154362416107385e-05,
      "loss": 0.0451,
      "step": 460
    },
    {
      "epoch": 1.0514541387024607,
      "grad_norm": 0.2408004105091095,
      "learning_rate": 1.3005219985085757e-05,
      "loss": 0.041,
      "step": 470
    },
    {
      "epoch": 1.0738255033557047,
      "grad_norm": 0.25931766629219055,
      "learning_rate": 1.2856077554064133e-05,
      "loss": 0.0394,
      "step": 480
    },
    {
      "epoch": 1.0961968680089484,
      "grad_norm": 0.11966858059167862,
      "learning_rate": 1.2706935123042507e-05,
      "loss": 0.0381,
      "step": 490
    },
    {
      "epoch": 1.1185682326621924,
      "grad_norm": 0.1297951340675354,
      "learning_rate": 1.255779269202088e-05,
      "loss": 0.037,
      "step": 500
    },
    {
      "epoch": 1.1409395973154361,
      "grad_norm": 0.1312883198261261,
      "learning_rate": 1.2408650260999256e-05,
      "loss": 0.0365,
      "step": 510
    },
    {
      "epoch": 1.1633109619686801,
      "grad_norm": 0.10841250419616699,
      "learning_rate": 1.225950782997763e-05,
      "loss": 0.036,
      "step": 520
    },
    {
      "epoch": 1.1856823266219239,
      "grad_norm": 0.0929950401186943,
      "learning_rate": 1.2110365398956004e-05,
      "loss": 0.0358,
      "step": 530
    },
    {
      "epoch": 1.2080536912751678,
      "grad_norm": 0.1097172349691391,
      "learning_rate": 1.1961222967934378e-05,
      "loss": 0.0353,
      "step": 540
    },
    {
      "epoch": 1.2304250559284116,
      "grad_norm": 0.13200995326042175,
      "learning_rate": 1.1812080536912754e-05,
      "loss": 0.035,
      "step": 550
    },
    {
      "epoch": 1.2527964205816555,
      "grad_norm": 0.08718805760145187,
      "learning_rate": 1.1662938105891126e-05,
      "loss": 0.0346,
      "step": 560
    },
    {
      "epoch": 1.2751677852348993,
      "grad_norm": 0.09197883307933807,
      "learning_rate": 1.15137956748695e-05,
      "loss": 0.0343,
      "step": 570
    },
    {
      "epoch": 1.2975391498881432,
      "grad_norm": 0.08808453381061554,
      "learning_rate": 1.1364653243847876e-05,
      "loss": 0.034,
      "step": 580
    },
    {
      "epoch": 1.319910514541387,
      "grad_norm": 0.09164698421955109,
      "learning_rate": 1.1215510812826249e-05,
      "loss": 0.0337,
      "step": 590
    }
  ],
  "logging_steps": 10,
  "max_steps": 1341,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 951263220989952.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
